{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Agoritm Naive Bayes pentru prezentare.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEA7DMXwnqeG",
        "outputId": "f2581869-7bf8-446d-b37b-8c667e09c517"
      },
      "source": [
        "!rm -f *.py\n",
        "!wget https://raw.githubusercontent.com/artificial-intelligence-ml-cti/ml_cti/main/proiect/dale_chall.py"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 18:03:01--  https://raw.githubusercontent.com/artificial-intelligence-ml-cti/ml_cti/main/proiect/dale_chall.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27456 (27K) [text/plain]\n",
            "Saving to: ‘dale_chall.py’\n",
            "\n",
            "dale_chall.py       100%[===================>]  26.81K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-11-22 18:03:01 (22.7 MB/s) - ‘dale_chall.py’ saved [27456/27456]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wvjMJ8PoKBv",
        "outputId": "c58598be-0026-45ef-c3a3-b4e26a270b8d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uto4F2K7omAQ",
        "outputId": "6240d24c-2958-42c2-9c01-2ea5833a58b2"
      },
      "source": [
        "!rm -rf data*\n",
        "!wget https://github.com/artificial-intelligence-ml-cti/ml_cti/raw/main/proiect/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 18:03:02--  https://github.com/artificial-intelligence-ml-cti/ml_cti/raw/main/proiect/data.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/artificial-intelligence-ml-cti/ml_cti/main/proiect/data.zip [following]\n",
            "--2021-11-22 18:03:02--  https://raw.githubusercontent.com/artificial-intelligence-ml-cti/ml_cti/main/proiect/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 741506 (724K) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 724.13K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-11-22 18:03:02 (24.0 MB/s) - ‘data.zip’ saved [741506/741506]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/test.xlsx          \n",
            "  inflating: data/train.xlsx         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpn-mkRNow6g",
        "outputId": "ed5a02e6-8177-4a2e-d0e6-c98b3026654e"
      },
      "source": [
        "!echo \"***\\n lista fisiere :\"\n",
        "!ls data\n",
        "!readlink -f data/"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***\\n lista fisiere :\n",
            "test.xlsx  train.xlsx\n",
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua653Nv-qF_g",
        "outputId": "22704ba1-828a-483a-b80d-9b12f3d04ef1"
      },
      "source": [
        "!pip install pyphen nltk pandas sklearn openpyxl"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (2.5.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ZGwqVIo7hv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "from dale_chall import DALE_CHALL\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl0qblFOqaxL",
        "outputId": "c53aa3fc-d592-465d-8215-a150629db170"
      },
      "source": [
        "dtypes = {\"sentence\":\"string\", \"token\" : \"string\", \"complexity\" : \"float64\"}\n",
        "train = pd.read_excel('/content/data/train.xlsx', dtype = dtypes, keep_default_na = False)\n",
        "test = pd.read_excel('/content/data/test.xlsx', dtype = dtypes, keep_default_na = False)\n",
        "\n",
        "print('train.data: ', train.shape)\n",
        "print('test.data: ', test.shape)\n",
        "\n",
        "print(train.columns)\n",
        "\n",
        "print(train['corpus'].unique())\n",
        "\n",
        "print(len(train['token'].unique()))\n",
        "\n",
        "print(len(train))\n",
        "\n",
        "print(train.iloc[0])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.data:  (7662, 4)\n",
            "test.data:  (1338, 3)\n",
            "Index(['corpus', 'sentence', 'token', 'complex'], dtype='object')\n",
            "['bible' 'biomed' 'europarl']\n",
            "3487\n",
            "7662\n",
            "corpus                                                  bible\n",
            "sentence    Behold, there came up out of the river seven c...\n",
            "token                                                   river\n",
            "complex                                                     0\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD0s7P1jsddY",
        "outputId": "878283ef-9c34-4ccc-b942-36148d9b905e"
      },
      "source": [
        "\n",
        "def is_dale_chall(word):\n",
        "  return int(word in DALE_CHALL)\n",
        " \n",
        "def is_title(word):\n",
        "  return int(word.istitle())\n",
        "\n",
        "\n",
        "def up_letters(word):\n",
        "  nr = 0\n",
        "  cnt=0\n",
        "  for letter in word:\n",
        "    cnt +=1\n",
        "    if letter.isupper():\n",
        "      nr += 1\n",
        "  return nr/cnt\n",
        "\n",
        "def litere_rare(word):\n",
        "  litererare = 'jqxzJQXZ'\n",
        "  nr = 0\n",
        "  for letter in word:\n",
        "    if letter in litererare:\n",
        "      nr += 1\n",
        "  return nr\n",
        "\n",
        "def cifre(word):\n",
        "  cifre = '0123456789'\n",
        "  nr = 0\n",
        "  for letter in word:\n",
        "    if letter in word:\n",
        "      return 1\n",
        "    \n",
        "  return 0\n",
        "\n",
        "vowels = 'aeiouw'\n",
        "def nr_vowels(word):\n",
        "  nr = 0\n",
        "  for chr in word:\n",
        "    if chr in vowels:\n",
        "      nr+=1\n",
        "  return nr\n",
        "\n",
        "def nr_synsets(word):\n",
        "  return len(wn.synsets(word))/10\n",
        "\n",
        "def get_word_structure_features(word):\n",
        "  features = []\n",
        "  features.append(is_dale_chall(word))\n",
        "  features.append(is_title(word))\n",
        "  features.append(up_letters(word))\n",
        "  features.append(nr_vowels(word))\n",
        "  features.append(cifre(word))\n",
        "  features.append(litere_rare(word))\n",
        "  return np.array(features)\n",
        "\n",
        "def get_wordnet_features(word):\n",
        "  features = []\n",
        "  features.append(nr_synsets(word))\n",
        "  return np.array(features)\n",
        "\n",
        "def corpus_feature(corpus):\n",
        "  d = {\"bible\" : [1,0,0], \"europarl\" : [0,1,0], \"biomed\" : [0,0,1]}\n",
        "  return d[corpus]\n",
        "\n",
        "print(get_word_structure_features('to'))\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVDG-UTbmhkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719c502c-47d8-497f-8e44-1f7d11a93d51"
      },
      "source": [
        "def featurize(row):\n",
        "  word = row['token']\n",
        "  all_features=[]\n",
        "  all_features.extend(get_word_structure_features(word))\n",
        "  all_features.extend(get_wordnet_features(word))\n",
        "  all_features.extend(corpus_feature(row['corpus']))\n",
        "  return np.array(all_features)\n",
        "\n",
        "print(featurize(train.iloc[10]))\n",
        "\n",
        "def featurize_df(df):\n",
        "  nr_of_features = len(featurize(df.iloc[0]))\n",
        "  nr_of_examples = len(df)\n",
        "  features = np.zeros((nr_of_examples, nr_of_features))\n",
        "  for index, row in df.iterrows():\n",
        "    row_ftrs = featurize(row)\n",
        "    features[index, :] = row_ftrs\n",
        "  return features\n",
        "\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.  0.  0.  1.  1.  0.  0.2 1.  0.  0. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdqx8jMtk2cs"
      },
      "source": [
        "ACURATETE NAIVE BAYES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsbbKXqEga6U",
        "outputId": "b4570ccb-9897-4a15-b2fb-660af1e31e1e"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x_train, y_train, test_size = 0.1, random_state=42)\n",
        "gnb = GaussianNB()\n",
        "predz = gnb.fit(xtrain,ytrain).predict(xtest)\n",
        "\n",
        "print(balanced_accuracy_score(ytest,predz))\n",
        "\n",
        "preds = gnb.fit(x_train,y_train).predict(x_test)\n",
        "balanced_accuracy_score(ytest,predz)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7633282633282634\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7633282633282634"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtrDEUYaBqI7"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['id'] = test.index + len(train) + 1\n",
        "df['complex'] = preds\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 120,
      "outputs": []
    }
  ]
}