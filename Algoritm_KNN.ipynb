{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Algoritm KNN pentru prezentare.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEA7DMXwnqeG",
        "outputId": "e70f2ecb-c9ee-4481-d98e-064af10f317e"
      },
      "source": [
        "!rm -f *.py\n",
        "!wget https://raw.githubusercontent.com/artificial-intelligence-ml-cti/ml_cti/main/proiect/dale_chall.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 17:57:25--  https://raw.githubusercontent.com/artificial-intelligence-ml-cti/ml_cti/main/proiect/dale_chall.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27456 (27K) [text/plain]\n",
            "Saving to: ‘dale_chall.py’\n",
            "\n",
            "\rdale_chall.py         0%[                    ]       0  --.-KB/s               \rdale_chall.py       100%[===================>]  26.81K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-11-22 17:57:25 (24.3 MB/s) - ‘dale_chall.py’ saved [27456/27456]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wvjMJ8PoKBv",
        "outputId": "259d9676-f7ec-45f3-f257-da719a15fbbb"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uto4F2K7omAQ",
        "outputId": "b7ff2c9f-b1e8-4db4-b650-f4ab6645a38e"
      },
      "source": [
        "!rm -rf data*\n",
        "!wget https://github.com/artificial-intelligence-ml-cti/ml_cti/raw/main/proiect/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 17:57:25--  https://github.com/artificial-intelligence-ml-cti/ml_cti/raw/main/proiect/data.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/artificial-intelligence-ml-cti/ml_cti/main/proiect/data.zip [following]\n",
            "--2021-11-22 17:57:26--  https://raw.githubusercontent.com/artificial-intelligence-ml-cti/ml_cti/main/proiect/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 741506 (724K) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 724.13K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-11-22 17:57:26 (23.9 MB/s) - ‘data.zip’ saved [741506/741506]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/test.xlsx          \n",
            "  inflating: data/train.xlsx         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpn-mkRNow6g",
        "outputId": "021d41d0-6a32-4d7f-9eff-a10ff1343f38"
      },
      "source": [
        "!echo \"***\\n lista fisiere :\"\n",
        "!ls data\n",
        "!readlink -f data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***\\n lista fisiere :\n",
            "test.xlsx  train.xlsx\n",
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua653Nv-qF_g",
        "outputId": "5b735a32-2fc3-46c2-bfe4-a2d74c7109f7"
      },
      "source": [
        "!pip install pyphen nltk pandas sklearn openpyxl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (2.5.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ZGwqVIo7hv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "from dale_chall import DALE_CHALL\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl0qblFOqaxL",
        "outputId": "045b3f9f-4e7b-4dd6-849d-57c260673ecd"
      },
      "source": [
        "dtypes = {\"sentence\":\"string\", \"token\" : \"string\", \"complexity\" : \"float64\"}\n",
        "train = pd.read_excel('/content/data/train.xlsx', dtype = dtypes, keep_default_na = False)\n",
        "test = pd.read_excel('/content/data/test.xlsx', dtype = dtypes, keep_default_na = False)\n",
        "\n",
        "print('train.data: ', train.shape)\n",
        "print('test.data: ', test.shape)\n",
        "print(train.columns)\n",
        "print(train['corpus'].unique())\n",
        "print(len(train['token'].unique()))\n",
        "print(len(train))\n",
        "\n",
        "print(train.iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.data:  (7662, 4)\n",
            "test.data:  (1338, 3)\n",
            "Index(['corpus', 'sentence', 'token', 'complex'], dtype='object')\n",
            "['bible' 'biomed' 'europarl']\n",
            "3487\n",
            "7662\n",
            "corpus                                                  bible\n",
            "sentence    Behold, there came up out of the river seven c...\n",
            "token                                                   river\n",
            "complex                                                     0\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l0a6c0boXXF"
      },
      "source": [
        "WORD COUNTER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsAOQQfJoo8R",
        "outputId": "97379b44-6c3d-48e9-bc1c-866f8e13abc7"
      },
      "source": [
        "import string\n",
        "\n",
        "propozitii=''\n",
        "\n",
        "for index in range(len(train)):\n",
        "  propozitii = propozitii+ ' ' +train.iloc[index]['sentence']\n",
        "\n",
        "for index in range(len(test)):\n",
        "  propozitii = propozitii+ ' ' +test.iloc[index]['sentence']\n",
        "\n",
        "punctuations = ',!?\".'\n",
        "nopunct=\"\"\n",
        "\n",
        "for char in propozitii:\n",
        "  if char not in punctuations:\n",
        "    nopunct = nopunct + char\n",
        "\n",
        "propozitii = nopunct\n",
        "propozitii = propozitii.lower()\n",
        "\n",
        "\n",
        "\n",
        "def word_count(str):\n",
        "  counts = dict()\n",
        "  words = str.split()\n",
        "\n",
        "  for word in words:\n",
        "    if word in counts:\n",
        "      counts[word] += 1\n",
        "    else:\n",
        "      counts[word] = 1\n",
        "  return counts\n",
        "\n",
        "\n",
        "\n",
        "lista = list(word_count(propozitii).items())\n",
        "wordcount = np.array(lista)\n",
        "\n",
        "totalcuvinte = 0\n",
        "\n",
        "for i in range(len(wordcount)):\n",
        "  totalcuvinte = totalcuvinte + wordcount[i][1].astype(np.int)\n",
        "\n",
        "print(wordcount)\n",
        "print(np.where(wordcount == 'behold'))\n",
        "def numar_aparitii(word):\n",
        "  if word in wordcount:\n",
        "    index = np.where(wordcount == word)\n",
        "    nrap = wordcount[index[0],1].astype('float64') \n",
        "    nrap = nrap.astype('float64')\n",
        "\n",
        "    nrap[0] = round(nrap[0]*100/totalcuvinte,4)\n",
        "  \n",
        " \n",
        "  \n",
        "    return nrap[0]\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['behold' '118']\n",
            " ['there' '435']\n",
            " ['came' '136']\n",
            " ...\n",
            " ['rye' '1']\n",
            " ['durum' '1']\n",
            " ['c4-0292/98-98/0107(cns))ii' '1']]\n",
            "(array([0]), array([0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD0s7P1jsddY",
        "outputId": "18203468-f5f2-4f17-8d60-659d0473c43a"
      },
      "source": [
        "\n",
        "def is_dale_chall(word):\n",
        "  return int(word in DALE_CHALL)\n",
        " \n",
        "def is_title(word):\n",
        "  if int(word.istitle())==0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def up_letters(word):\n",
        "  nr = 0\n",
        "  cnt=0\n",
        "  for letter in word:\n",
        "    cnt +=1\n",
        "    if letter.isupper():\n",
        "      nr += 1\n",
        "  if nr == 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return nr/10\n",
        "\n",
        "def litere_rare(word):\n",
        "  litere = 'jqzxJQZX'\n",
        "  for letter in word:\n",
        "    if letter in litere:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "def corpus_feature(corpus):\n",
        "  d = {\"bible\" : [1,0,0], \"europarl\" : [0,1,0], \"biomed\" : [0,0,1]}\n",
        "  return d[corpus]\n",
        "\n",
        "def nr_synsets(word):\n",
        "  return len(wn.synsets(word))/10\n",
        "\n",
        "def get_wordnet_features(word):\n",
        "  features = []\n",
        "  features.append(nr_synsets(word))\n",
        "  return np.array(features)/10\n",
        "\n",
        "\n",
        "def get_word_structure_features(word):\n",
        "  features = []\n",
        "  features.append(is_dale_chall(word))\n",
        "  features.append(is_title(word))\n",
        "  features.append(up_letters(word))\n",
        "  features.append(litere_rare(word))\n",
        "  features.append(len(word)/10)\n",
        "  features.append(numar_aparitii(word))\n",
        "  return np.array(features)\n",
        "\n",
        "print(get_word_structure_features('to'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.     1.     1.     0.     0.2    2.5261]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVDG-UTbmhkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82547763-ed4b-49d6-cbaa-350ec6c26e72"
      },
      "source": [
        "def featurize(row):\n",
        "  word = row['token']\n",
        "  all_features=[]\n",
        "  all_features.extend(get_word_structure_features(word))\n",
        "  all_features.extend(get_wordnet_features(word))\n",
        "  all_features.extend(corpus_feature(row['corpus']))\n",
        "  return np.array(all_features)\n",
        "\n",
        "print(featurize(train.iloc[10]))\n",
        "\n",
        "def featurize_df(df):\n",
        "  nr_of_features = len(featurize(df.iloc[0]))\n",
        "  nr_of_examples = len(df)\n",
        "  features = np.zeros((nr_of_examples, nr_of_features))\n",
        "  for index, row in df.iterrows():\n",
        "    row_ftrs = featurize(row)\n",
        "    features[index, :] = row_ftrs\n",
        "  return features\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.     1.     1.     0.     0.4    0.0326 0.02   1.     0.     0.    ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSo7aKl9mjxh",
        "outputId": "c4f2a12c-5972-4f16-c4d3-80fbb885983b"
      },
      "source": [
        "\n",
        "x_train = featurize_df(train)\n",
        "y_train = train['complex'].values\n",
        "\n",
        "x_test = featurize_df(test)\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=7)\n",
        "model.fit(x_train, y_train)\n",
        "preds = model.predict(x_test)\n",
        "print(preds)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKUnRYl5kzw5"
      },
      "source": [
        "ACURATETE KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7HzNmqedyHC",
        "outputId": "415e76ea-45ee-45b5-d588-87750817f1cc"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x_train, y_train, test_size = 0.1, random_state=42)\n",
        "\n",
        "print(xtrain.shape)\n",
        "print(xtest.shape)\n",
        "print(np.bincount(ytrain))\n",
        "print(np.bincount(ytest))\n",
        "for index in range (1,21):\n",
        "  model = KNeighborsClassifier(n_neighbors=index)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  predz = model.predict(xtest)\n",
        "\n",
        "  print(balanced_accuracy_score(ytest,predz))\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=1)\n",
        "model.fit(x_train, y_train)\n",
        "preds = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6895, 10)\n",
            "(767, 10)\n",
            "[6219  676]\n",
            "[693  74]\n",
            "0.7624020124020123\n",
            "0.6834171834171834\n",
            "0.7184489684489684\n",
            "0.6723314223314223\n",
            "0.6728579228579228\n",
            "0.6535041535041535\n",
            "0.6687239187239187\n",
            "0.6453043953043953\n",
            "0.6438613938613938\n",
            "0.6407121407121407\n",
            "0.6371046371046372\n",
            "0.6296263796263797\n",
            "0.6371046371046372\n",
            "0.6204418704418704\n",
            "0.6325123825123825\n",
            "0.6151281151281152\n",
            "0.6204418704418704\n",
            "0.6158496158496158\n",
            "0.6346768846768847\n",
            "0.6226063726063726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtrDEUYaBqI7"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['id'] = test.index + len(train) + 1\n",
        "df['complex'] = preds\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}